{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Performance\n",
    "\n",
    "This is the demonstration notebook for E-Commerce Data (Re)-Mapper developed by Alari Varmann from Integrify.\n",
    "How to run : To see the application running without human intervention, the Docker container has been built, in which you can choose between 3 models.\n",
    "Right now, this will be asked from the user in the terminal, but ArgumentParser could also be used.\n",
    "The models may predict wrong sometimes many in a row even, but it has been double validated on the existing data that the **validation set performance** of all of them should be **above 92%**, while the ones using the processed features have performance of around **98%+** for all the most common category tree paths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "Right now, there may be some performance slowdown issues, depdendent on the environment. \n",
    "The runtime speed of predictions in Local conda environment has been around 3 seconds per iteration, or around 0.3 iterations per second.\n",
    "However on `ml.p2.xlarge` instance on `AWS`, the typical performance should be between 4-10 iterations per second, so at least 10 times faster.\n",
    "This is strange because the machine tested on locally is Octa-core machine, and the container uses the CPU version of Pytorch.\n",
    "For the sake of simplicity and saving of the resources, more experiments on runtime environments should be conducted.\n",
    "\n",
    "UPDATE : The Docker container has been run on `ml.p2.xlarge` instance and the speed was around 2-3 iterations per second. Thus, a potential gain of around two times could be achieved.\n",
    "In case of wishing higher performance, one potential bug in the original source library should try to be fixed (please check the end of the document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the Predict Function \n",
    "The predict function used in this case is a local method for `RNNLearner` which is a Recurrent Neural Network model class.\n",
    "It is documented [here](https://docs.fast.ai/text.learner.html#LanguageLearner.predict)\n",
    "```python\n",
    "predict(text:str, n_words:int=1, no_unk:bool=True, temperature:float=1.0, min_p:float=None, sep:str=' ', decoder='decode_spec_tokens')\n",
    "``` \n",
    "\n",
    "### Run all cells up to the cell test_data_full.head() \n",
    "#### Predictions from Model 1 : 6_full (6 full processed features, version 1)\n",
    "**and then come back here to run**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combined_name_description    mille notti-oceano aluslakana 270x270cm, hiekk...\n",
       "cleaned_description          oceano aluslakana 270x270cm, hiekka frÃ¥n mille...\n",
       "brand                                                              Mille Notti\n",
       "original_tree                Tekstiilit & Matot|Makuuhuonetekstiilit|Alusla...\n",
       "provider                                                                 Rum21\n",
       "summary                                                                       \n",
       "Name: 440838, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurerow = test_data_full.iloc[0]\n",
    "test_data_full.iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_one_prediction(model, feature_row):\n",
    "    \"\"\"This function returns one prediction per Pandas Dataframe row\"\"\"\n",
    "    one_prediction = model.predict(feature_row)[0].obj\n",
    "    return one_prediction\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data for FULL model  read and loaded!\n",
      "Test data added to the final model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test data for FULL model  read and loaded!\")\n",
    "#final_learner_2.data.add_test(featurerow)\n",
    "print(\"Test data added to the final model\")\n",
    "\n",
    "\n",
    "\n",
    "get_one_prediction(model=final_learner_2, feature_row=featurerow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category 569"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_learner_2.predict(featurerow)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_learner_2.predict(featurerow)[0].obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is how the predict function can be used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Guide to Process The Data and Get Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 0. Imports and Set Raw (Products) Data Location Definition\n",
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "ROOT = os.getcwd()\n",
    "products_path = os.path.join(ROOT,\"data\",\"products.csv\")\n",
    "```\n",
    "\n",
    "> 1. Run the Utility Functions Cell (Next cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Getting Models. \n",
    "\n",
    "Download the Databunch only if you wish to validate the predictions on the whole validation sets yourself\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT : FIRST CREATE \"data\" , \"models\" and \"bunches_full\" folders to the root of the project and download the products.csv file into data folder\n",
    "### Then download all the models and name them this way:\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "LOCAL_MODEL_PATH = os.path.join(ROOT,\"models\")\n",
    "\n",
    "cl_bunch_path = os.path.join(ROOT,\"bunches_full\",\"latest_cl_bunch_FULL_bs48\")\n",
    "\n",
    "cl_bunch_path_remote_path=\"https://filedn.com/lK1VhM9GbBxVlERr9KFjD4B/ecommerce/databunches/latest_cl_bunch_FULL_bs48\"\n",
    "\n",
    "final_model_path_2= os.path.join(LOCAL_MODEL_PATH,\"final_model_6_full\")\n",
    "final_model_path_2_remote = \"https://filedn.com/lK1VhM9GbBxVlERr9KFjD4B/ecommerce/e_commerce_predictor/models/6_features_80pc_final.pkl\"\n",
    " \n",
    " \n",
    "final_model_path_1= os.path.join(LOCAL_MODEL_PATH,\"pre_model_6_full\")\n",
    "final_model_path_1_remote = \"https://filedn.com/lK1VhM9GbBxVlERr9KFjD4B/ecommerce/e_commerce_predictor/models/6_features_80pc.pkl\"\n",
    "   \n",
    "   \n",
    "raw_model_path = os.path.join(LOCAL_MODEL_PATH,\"6_raw_features_85pc\") \n",
    "raw_model_path_remote = \"https://filedn.com/lK1VhM9GbBxVlERr9KFjD4B/ecommerce/e_commerce_predictor/models/6_raw_features_85pc.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 RUN Utility Functions for Preparing Data for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "import ntpath\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "#ROOT = \"/home/ec2-user/SageMaker/e_commerce_hierarchical/e_commerce_project/\"\n",
    "\n",
    "\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "products_path = os.path.join(ROOT,\"data\",\"products.csv\")\n",
    "LOCAL_MODEL_PATH = os.path.join(ROOT,\"models\")\n",
    "\n",
    "\n",
    "\n",
    "def path_leaf(path):\n",
    "    \"\"\"This function gives the leaf of a path\"\"\"\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "\n",
    "def subtract(a, b):\n",
    "    \"\"\"This function subtracts two paths, used for loading purposes\"\"\"\n",
    "    return \"\".join(a.rsplit(b))\n",
    "\n",
    "def produce_doublet_from_path(path):\n",
    "    \"\"\"Function where the last two functions are used. It splits one path into two\n",
    "    from the leaf. \"\"\"\n",
    "    name = path_leaf(path)\n",
    "    base = subtract(path,name)\n",
    "    print(f\"Base path is {base}\")\n",
    "    print(f\"Object name is {name}\")\n",
    "    return name,base\n",
    "\n",
    "\n",
    "def replace_global_missing_features_with_empty(df, feature_names):\n",
    "    \"\"\"This function replaces missing, NAN or empty values in Pandas dataframe with empty string\"\"\"\n",
    "    df.loc[:, feature_names] = df.loc[:, feature_names].replace(np.nan, '', regex=True).fillna(\"\")\n",
    "    return df\n",
    "\n",
    "def select_globally_defined_features_and_target(data, label_name,feature_names):\n",
    "    \"\"\"Selects features and labels in Pandas Dataframe by their name(s)\"\"\"\n",
    "    labels = data.loc[:, label_name]\n",
    "    features = data.loc[:, feature_names].reset_index(drop=True)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def drop_if_exists(df, cols):\n",
    "    \"\"\"Drops a column in Pandas dataframe only if it exists there\"\"\"\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "def text_cleaner(text):\n",
    "    \"\"\"This is the only actual preprocessing function used. It's a list of regex rules,\n",
    "    each rule is applied one-by-one, then whitespace is trimmed and text is lower cased.\"\"\"\n",
    "    rules = [\n",
    "        {r'>\\s+': u'>'},  # remove spaces after a tag opens or closes\n",
    "        {r'\\s+': u' '},  # replace consecutive spaces\n",
    "        {r'\\s*<br\\s*/?>\\s*': u'\\n'},  # newline after a <br>\n",
    "        {r'</(div)\\s*>\\s*': u'\\n'},  # newline after </p> and </div> and <h1/>...\n",
    "        {r'</(p|h\\d)\\s*>\\s*': u'\\n\\n'},  # newline after </p> and </div> and <h1/>...\n",
    "        {r'<head>.*<\\s*(/head|body)[^>]*>': u''},  # remove <head> to </head>\n",
    "        {r'<a\\s+href=\"([^\"]+)\"[^>]*>.*</a>': r'\\1'},  # show links instead of texts\n",
    "        {r'[ \\t]*<[^<]*?/?>': u''},  # remove remaining tags\n",
    "        {r'^\\s+': u''}  # remove spaces at the beginning\n",
    "    ]\n",
    "    for rule in rules:\n",
    "        for (k, v) in rule.items():\n",
    "            regex = re.compile(k)\n",
    "            text = regex.sub(v, text)\n",
    "    text = text.rstrip()\n",
    "    return text.lower()\n",
    "\n",
    "def preprocessing_for_prediction(df, target_category, model_ver):\n",
    "    \"\"\" This function generates data, target_category name and feature_names list \\\n",
    "    for to be used in the prediction function later. All features are of string data type!\"\"\"\n",
    "    df = df.loc[:, [\"name\", \"description\", \"summary\", \"original_tree\", \"brand\", \"provider\", target_category]]\n",
    "    # the features above are all the features defined in the 6_raw model\n",
    "    if model_ver == \"6_raw\":\n",
    "        feature_names = df.columns.tolist()\n",
    "        feature_names.remove(target_category)\n",
    "        print(f\"Feature names are {feature_names}\")\n",
    "        df.loc[:, target_category] = df.loc[:, target_category].astype(int)\n",
    "        print(\"Production mode running on trivial NAN -> \"\" preprocessing.\")\n",
    "        print(f\"Before exiting step 1, the columns are {df.columns.tolist()}\")\n",
    "        print(f\"\"\"Check : the features have to be the following : \\n \n",
    "        name, description, summary, original, tree, brand, provider\"\"\")\n",
    "    elif model_ver == \"6_full\":\n",
    "        df[\"combined_name_description\"] = df.progress_apply(\n",
    "            lambda row: str(row[\"name\"]).lower() + str(row[\"description\"]), axis=1)\n",
    "        df[\"combined_name_description\"] = df.progress_apply(lambda row: text_cleaner(str(\n",
    "            row[\"combined_name_description\"]).lower()), axis=1)\n",
    "        df = df.rename(columns={\"description\": \"cleaned_description\"}, inplace=False)\n",
    "        df = drop_if_exists(df, cols=[\"name\"])\n",
    "        df[\"cleaned_description\"] = df.progress_apply(lambda row: text_cleaner(str(row[\"cleaned_description\"]).lower()),\n",
    "                                                      axis=1)\n",
    "        df = df.loc[:,\n",
    "             [\"combined_name_description\", \"cleaned_description\", \"brand\", \"original_tree\", \"provider\", \"summary\",\n",
    "              target_category]]\n",
    "        feature_names = df.columns.tolist()\n",
    "        feature_names.remove(target_category)\n",
    "    df = replace_global_missing_features_with_empty(df, feature_names=feature_names)\n",
    "    print(f\"The 6 feature model has columns like {df.columns.tolist()}\")\n",
    "\n",
    "    return {\"data\": df, \"target_category\": target_category, \"feature_names\": feature_names}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Use the function `load_test_data` to prepare the data from model version and raw data path. This is defined in the next cell.\n",
    "\n",
    " ```python\n",
    "def load_test_data(model_ver,path=products_path):\n",
    "    \"\"\"The idea of this function is to prepare all the data for testing the prediction model.\n",
    "    The input arguments are model_ver (model version, either 6_full or 6_raw and\n",
    "    path of the raw Pandas dataframe with the products.\n",
    "    It returns both the data to be tested (Pandas Dataframe) and the Series of the target column (mapped_id)\"\"\")\n",
    "    #if amountlines != -1:\n",
    "    #    rows_to_keep = list(range(amountlines))\n",
    "    #    df = pd.read_csv(path, skiprows=lambda x: x not in rows_to_keep)\n",
    "    df = pd.read_csv(path)\n",
    "    test_data = df.sample(1000)\n",
    "    print(\"Test data sampled, starting preprocessing\")\n",
    "    tqdm_notebook().pandas()\n",
    "    preproc_dict=preprocessing_for_prediction(df=test_data, target_category=\"mapped_id\", model_ver=model_ver)\n",
    "    test_data = preproc_dict[\"data\"]\n",
    "    print(\"Test data preprocessed\")\n",
    "    test_target = test_data.loc[:,\"mapped_id\"]\n",
    "    test_data = test_data.drop(\"mapped_id\",axis=1) #drop_if_exists(test_data,\"mapped_id\")\n",
    "    return test_data,test_target\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data sampled, starting preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c8dcdaba5848049ea3d1063ab462e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5340cb9b969940d49365bff3dc37574e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b47d3e1ac0c4c22a359a1197af0576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6a2fa2305047dd91020a9a978ebc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 6 feature model has columns like ['combined_name_description', 'cleaned_description', 'brand', 'original_tree', 'provider', 'summary', 'mapped_id']\n",
      "Test data preprocessed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#ROOT = \"/home/ec2-user/SageMaker/e_commerce_hierarchical/e_commerce_project/app\"\n",
    "ROOT = os.getcwd()\n",
    "products_path = os.path.join(ROOT,\"data\",\"products.csv\")\n",
    "\n",
    "def load_test_data(model_ver,path=products_path,subsample=None):\n",
    "    \"\"\"The idea of this function is to prepare all the data for testing the prediction model.\n",
    "    The input arguments are model_ver (model version, either 6_full or 6_raw and\n",
    "    path of the raw Pandas dataframe with the products.\n",
    "    It returns both the data to be tested (Pandas Dataframe) and the Series of the target column (mapped_id)\"\"\"\n",
    "    #if amountlines != -1:\n",
    "    #    rows_to_keep = list(range(amountlines))\n",
    "    #    df = pd.read_csv(path, skiprows=lambda x: x not in rows_to_keep)\n",
    "    df = pd.read_csv(path)\n",
    "    if subsample is not None:\n",
    "        test_data = df.sample(subsample)\n",
    "    print(\"Test data sampled, starting preprocessing\")\n",
    "    tqdm_notebook().pandas()\n",
    "    preproc_dict=preprocessing_for_prediction(df=test_data, target_category=\"mapped_id\", model_ver=model_ver)\n",
    "    test_data = preproc_dict[\"data\"]\n",
    "    print(\"Test data preprocessed\")\n",
    "    test_target = test_data.loc[:,\"mapped_id\"]\n",
    "    test_data = test_data.drop(\"mapped_id\",axis=1) #drop_if_exists(test_data,\"mapped_id\")\n",
    "    return test_data,test_target\n",
    "\n",
    "test_data_full,test_target = load_test_data(model_ver=\"6_full\",path=products_path,subsample=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">2. Initialize the paths and Load the fast.AI prediction model\n",
    "\n",
    "```python\n",
    "def test_learner_loading(path=final_model_path):\n",
    "    \"\"\"Given the path for the fast.AI prediction model, it loads and returns it\"\"\"\n",
    "    name,base = produce_doublet_from_path(path)\n",
    "    loaded_model = load_learner(path=base,file=f\"{name}.pkl\")\n",
    "    return loaded_model\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fastai.text import *\n",
    "\n",
    "def test_learner_loading(path):\n",
    "    \"\"\"Given the path for the fast.AI prediction model, it loads and returns it\"\"\"\n",
    "    name,base = produce_doublet_from_path(path)\n",
    "    loaded_model = load_learner(path=base,file=f\"{name}.pkl\")\n",
    "    return loaded_model\n",
    "\n",
    "LOCAL_MODEL_PATH = os.path.join(ROOT,\"models\")\n",
    "\n",
    "final_model_path= os.path.join(LOCAL_MODEL_PATH,\"final_model_6_full\")\n",
    "final_model_path_2= os.path.join(LOCAL_MODEL_PATH,\"final_model_6_full\")\n",
    "final_model_path_1= os.path.join(LOCAL_MODEL_PATH,\"pre_model_6_full\")\n",
    "raw_model_path = os.path.join(LOCAL_MODEL_PATH,\"6_raw_features_85pc\") \n",
    "\n",
    "print(\"databunch loaded\")\n",
    "final_learner_2 = test_learner_loading(path=final_model_path_2)\n",
    "final_learner_1 = test_learner_loading(path=final_model_path_1)\n",
    "raw_feature_learner = test_learner_loading(path=raw_model_path)\n",
    "\n",
    "print(\"All models loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">3. Load the test data and use the following function to obtain the predictions\n",
    "```python\n",
    "obtain_test_predictions(model=final_learner_2, features=test_data_full, how_many_preds=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_one_prediction(model, feature_row):\n",
    "    \"\"\"This function returns one prediction per Pandas Dataframe row\"\"\"\n",
    "    one_prediction = model.predict(feature_row)[0].obj\n",
    "    return one_prediction\n",
    "\n",
    "\n",
    "def obtain_test_predictions(model, features, how_many_preds=1000):\n",
    "    \"\"\"This function applies the prediction function to the features Dataframe, row by row\"\"\"\n",
    "    featurecount = features.shape[1]\n",
    "    features = features.reset_index(drop=True)\n",
    "    for i, feature_row in tqdm(features.iterrows(), total=features.shape[0]):\n",
    "        prediction = get_one_prediction(model, feature_row)\n",
    "        print(f\"Prediction {i} is {prediction}\")\n",
    "        if i == how_many_preds:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions from Model 1 : 6_full (6 full processed features, version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_name_description</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_tree</th>\n",
       "      <th>provider</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440838</th>\n",
       "      <td>mille notti-oceano aluslakana 270x270cm, hiekk...</td>\n",
       "      <td>oceano aluslakana 270x270cm, hiekka frÃ¥n mille...</td>\n",
       "      <td>Mille Notti</td>\n",
       "      <td>Tekstiilit &amp; Matot|Makuuhuonetekstiilit|Alusla...</td>\n",
       "      <td>Rum21</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49873</th>\n",
       "      <td>sheer tint moisture spf20 light 40 mluv-suojan...</td>\n",
       "      <td>uv-suojan sisÃ¤ltÃ¤vÃ¤ sheer tint moisture Ã¶ljytÃ¶...</td>\n",
       "      <td>Dermalogica</td>\n",
       "      <td>IHONHOITO|Kasvot|Ihotyypit|Normaali iho</td>\n",
       "      <td>Cocopanda</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549708</th>\n",
       "      <td>1:35 bm-21 grad multiple rocket launcherthe bm...</td>\n",
       "      <td>the bm-21 grad is a russian truck-mounted 122 ...</td>\n",
       "      <td>Trumpeter</td>\n",
       "      <td>Pienoismallit|Pienoismalli maakalusto|Maakalus...</td>\n",
       "      <td>Hobbylinna</td>\n",
       "      <td>The BM-21 Grad is a Russian truck-mounted 122 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556448</th>\n",
       "      <td>sl amr 4.7 nx eagle 1x12 19, tÃ¤ysjousitettu ma...</td>\n",
       "      <td>tehokas tÃ¤ysjousitus ja kevyt alumiinirunko. 1...</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>PyÃ¶rÃ¤ily|PolkupyÃ¶rÃ¤t|MaastopyÃ¶rÃ¤t</td>\n",
       "      <td>XXL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67703</th>\n",
       "      <td>pvc-housut or28507701021kuvaushousuissa on pai...</td>\n",
       "      <td>kuvaushousuissa on painonappi, vetoketju, vyÃ¶n...</td>\n",
       "      <td>Black Level</td>\n",
       "      <td>PVC Housut|Black Level</td>\n",
       "      <td>Antishop.fi</td>\n",
       "      <td>Kapealahkeiset pvc-housut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                combined_name_description  \\\n",
       "440838  mille notti-oceano aluslakana 270x270cm, hiekk...   \n",
       "49873   sheer tint moisture spf20 light 40 mluv-suojan...   \n",
       "549708  1:35 bm-21 grad multiple rocket launcherthe bm...   \n",
       "556448  sl amr 4.7 nx eagle 1x12 19, tÃ¤ysjousitettu ma...   \n",
       "67703   pvc-housut or28507701021kuvaushousuissa on pai...   \n",
       "\n",
       "                                      cleaned_description        brand  \\\n",
       "440838  oceano aluslakana 270x270cm, hiekka frÃ¥n mille...  Mille Notti   \n",
       "49873   uv-suojan sisÃ¤ltÃ¤vÃ¤ sheer tint moisture Ã¶ljytÃ¶...  Dermalogica   \n",
       "549708  the bm-21 grad is a russian truck-mounted 122 ...    Trumpeter   \n",
       "556448  tehokas tÃ¤ysjousitus ja kevyt alumiinirunko. 1...        Ghost   \n",
       "67703   kuvaushousuissa on painonappi, vetoketju, vyÃ¶n...  Black Level   \n",
       "\n",
       "                                            original_tree     provider  \\\n",
       "440838  Tekstiilit & Matot|Makuuhuonetekstiilit|Alusla...        Rum21   \n",
       "49873             IHONHOITO|Kasvot|Ihotyypit|Normaali iho    Cocopanda   \n",
       "549708  Pienoismallit|Pienoismalli maakalusto|Maakalus...   Hobbylinna   \n",
       "556448                  PyÃ¶rÃ¤ily|PolkupyÃ¶rÃ¤t|MaastopyÃ¶rÃ¤t          XXL   \n",
       "67703                              PVC Housut|Black Level  Antishop.fi   \n",
       "\n",
       "                                                  summary  \n",
       "440838                                                     \n",
       "49873                                                      \n",
       "549708  The BM-21 Grad is a Russian truck-mounted 122 ...  \n",
       "556448                                                     \n",
       "67703                           Kapealahkeiset pvc-housut  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:18,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data added to the final model\n",
      "Prediction 0 is 5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:00<02:33,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 is 5598\n",
      "Prediction 2 is 2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [00:00<02:11,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 3 is 778\n",
      "Prediction 4 is 5322\n",
      "Prediction 5 is 5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [00:00<02:04,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 6 is 5181\n",
      "Prediction 7 is 2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:01<02:06,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 8 is 201\n",
      "Prediction 9 is 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:01<02:31,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 10 is 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data for FULL model  read and loaded!\")\n",
    "final_learner_2.data.add_test(test_data_full)\n",
    "print(\"Test data added to the final model\")\n",
    "\n",
    "obtain_test_predictions(model=final_learner_2, features=test_data_full, how_many_preds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions from Model 2 : 6_full (6 full processed features, version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:20,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data added to the final model\n",
      "Prediction 0 is 5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:00<02:34,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 is 5598\n",
      "Prediction 2 is 2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [00:00<02:12,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 3 is 778\n",
      "Prediction 4 is 5322\n",
      "Prediction 5 is 5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [00:00<02:04,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 6 is 5181\n",
      "Prediction 7 is 2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:01<02:06,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 8 is 201\n",
      "Prediction 9 is 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:01<02:29,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 10 is 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data for FULL model read and loaded!\")\n",
    "final_learner_1.data.add_test(test_data_full)\n",
    "print(\"Test data added to the final model\")\n",
    "\n",
    "obtain_test_predictions(model=final_learner_1, features=test_data_full, how_many_preds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the Right Answers Are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5422, 5598, 2580, 778, 5322, 5598, 5181, 5609, 201, 187, 187]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target[0:11].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explanation : Since we don't have any new test data, it is possible that the model has seen these or similar data points during training*.\n",
    "\n",
    "Test the model with data points that are similar to the ones used in the dataset to get realistic estimates.\n",
    "Although the model will always give predictions, even if some columns are empty, it should be taken into account that if the predictions are off in this case, it might be partially caused by the missing column values, for which case they could be tried to be imputed.\n",
    "\n",
    "Sometimes even simple imputations can work, in other times even deep learning can be used for imputations.\n",
    "\n",
    "\n",
    "(*I have built full imputation pipelines before over nonrelational databases*)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions from Model 3 : 6_raw (6 raw features without preprocessing, except Nan->\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data sampled, starting preprocessing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0c8967dea3479c9460b1980d5c1389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names are ['name', 'description', 'summary', 'original_tree', 'brand', 'provider']\n",
      "Production mode running on trivial NAN ->  preprocessing.\n",
      "Before exiting step 1, the columns are ['name', 'description', 'summary', 'original_tree', 'brand', 'provider', 'mapped_id']\n",
      "Check : the features have to be the following : \n",
      " \n",
      "        name, description, summary, original, tree, brand, provider\n",
      "The 6 feature model has columns like ['name', 'description', 'summary', 'original_tree', 'brand', 'provider', 'mapped_id']\n",
      "Test data preprocessed\n",
      "Test data for RAW model read and loaded!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>original_tree</th>\n",
       "      <th>brand</th>\n",
       "      <th>provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329725</th>\n",
       "      <td>Jack &amp; Jones Jean Jacket Cj 077 Farkkutakki Me...</td>\n",
       "      <td>- Farkkutakki kahdella rintataskulla. Denim ei...</td>\n",
       "      <td></td>\n",
       "      <td>Clothing|Jackets|Denim Jacket</td>\n",
       "      <td>Jack &amp; Jones</td>\n",
       "      <td>Jack &amp; Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211611</th>\n",
       "      <td>Elliot Shirt Paita Bisnes Harmaa Bruuns Bazaar</td>\n",
       "      <td>Bruuns Bazaar Elliot Shirt</td>\n",
       "      <td></td>\n",
       "      <td>Men|Shirts</td>\n",
       "      <td>Bruuns Bazaar</td>\n",
       "      <td>Boozt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429815</th>\n",
       "      <td>System Professional - Sp Refined Texture Model...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hiustuotteet|Muotoilu|Muotoiluvoiteet</td>\n",
       "      <td>Wella</td>\n",
       "      <td>Nordicfeel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392760</th>\n",
       "      <td>Beamz Uskomaton Discosieni KaukosÃ¤Ã¤timellÃ¤</td>\n",
       "      <td>TÃ¤ssÃ¤ sellainen sieni, jota ei tule vastaa sie...</td>\n",
       "      <td></td>\n",
       "      <td>Discolaitteet</td>\n",
       "      <td>Beamz</td>\n",
       "      <td>Mulle Toi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17574</th>\n",
       "      <td>KengÃ¤t Les TropÃ©ziennes Par M Belarbi  Gloss</td>\n",
       "      <td>KengÃ¤t les tropÃ©ziennes par m belarbi gloss bl...</td>\n",
       "      <td></td>\n",
       "      <td>Naisten|KengÃ¤t|Bootsit</td>\n",
       "      <td>Les TropÃ©ziennes par M Belarbi</td>\n",
       "      <td>Spartoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "329725  Jack & Jones Jean Jacket Cj 077 Farkkutakki Me...   \n",
       "211611     Elliot Shirt Paita Bisnes Harmaa Bruuns Bazaar   \n",
       "429815  System Professional - Sp Refined Texture Model...   \n",
       "392760         Beamz Uskomaton Discosieni KaukosÃ¤Ã¤timellÃ¤   \n",
       "17574        KengÃ¤t Les TropÃ©ziennes Par M Belarbi  Gloss   \n",
       "\n",
       "                                              description summary  \\\n",
       "329725  - Farkkutakki kahdella rintataskulla. Denim ei...           \n",
       "211611                         Bruuns Bazaar Elliot Shirt           \n",
       "429815                                                              \n",
       "392760  TÃ¤ssÃ¤ sellainen sieni, jota ei tule vastaa sie...           \n",
       "17574   KengÃ¤t les tropÃ©ziennes par m belarbi gloss bl...           \n",
       "\n",
       "                                original_tree                           brand  \\\n",
       "329725          Clothing|Jackets|Denim Jacket                    Jack & Jones   \n",
       "211611                             Men|Shirts                   Bruuns Bazaar   \n",
       "429815  Hiustuotteet|Muotoilu|Muotoiluvoiteet                           Wella   \n",
       "392760                          Discolaitteet                           Beamz   \n",
       "17574                  Naisten|KengÃ¤t|Bootsit  Les TropÃ©ziennes par M Belarbi   \n",
       "\n",
       "            provider  \n",
       "329725  Jack & Jones  \n",
       "211611         Boozt  \n",
       "429815    Nordicfeel  \n",
       "392760     Mulle Toi  \n",
       "17574        Spartoo  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_raw,test_target2 = load_test_data(model_ver=\"6_raw\")\n",
    "print(\"Test data for RAW model read and loaded!\")\n",
    "test_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:07,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data added to the final model\n",
      "Prediction 0 is 5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1000 [00:00<01:54,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 is 212\n",
      "Prediction 2 is 1901\n",
      "Prediction 3 is 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:00<01:41,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 4 is 187\n",
      "Prediction 5 is 187\n",
      "Prediction 6 is 1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:01<02:25,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 7 is 204\n",
      "Prediction 8 is 6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [00:01<02:19,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 9 is 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [00:02<03:33,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 10 is 778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_feature_learner.data.add_test(test_data_raw)\n",
    "print(\"Test data added to the final model\")\n",
    "\n",
    "obtain_test_predictions(model=raw_feature_learner, features=test_data_raw, how_many_preds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The right answers in this case are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5598,  212, 1901,  408,  187,  187, 1604,  204, 6305,  188])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target2[0:10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Models and Suggestion for Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the answers are mostly right in both cases, but the models on processed data do better than the model trained on the raw data. \n",
    "\n",
    "*Important note : Even the presence of Nan's at prediction time did not seem to be a problem for the model. Just to be sure if possible, better always to remove NaNs*.\n",
    "\n",
    "Test rounds on small data showed model 1 performing the best, followed by model 2. Model 3 (on raw features) was off more often, behind the models 1 and 2.\n",
    "\n",
    "However, the validation accuracy of the raw features model should be somewhere around 90%+, but use this model only if it is really not possible to use processed features.\n",
    "\n",
    "Thus, \n",
    "\n",
    "**Recommendation right now is to use model 1. Probably there is no real difference either if model 2 is used, because both of them have cross-entropy loss of around 0.2 and validation accuracy over 96%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's Additional Stuff Below that is not needed for Production, but it's about\n",
    "> 1. Validation of predictions of the whole validation sets (classification bunches)\n",
    "> 2. How to make Predictions Faster (Acknowledging a possible bug // limitation in the source library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Validations on Full Validation Datasets (Fast.AI Databunches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, the databunches have to be either created or loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path is /home/ec2-user/SageMaker/e_commerce_hierarchical/e_commerce_project/code/bunches_full/\n",
      "Object name is latest_cl_bunch_FULL_bs48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#cl_bunch_path = os.path.join(ROOT,\"code\",\"bunches_full\",\"latest_cl_bunch_FULL_bs48\")\n",
    "\n",
    "\n",
    "\n",
    "def load_databunch(path=cl_bunch_path):\n",
    "    \"\"\"Given fast.AI classifier databunch path, it loads and returns it \"\"\"\n",
    "    cl_name, cl_base_path = produce_doublet_from_path(cl_bunch_path)\n",
    "    classifier_bunch = load_data(cl_base_path, file=cl_name) #,**{\"num_workers\":0}\n",
    "    return classifier_bunch\n",
    "\n",
    "def validate_on_validation_set(model,path=cl_bunch_path):\n",
    "    validation_bunch = load_databunch(path)\n",
    "    \"\"\"Given a Fast.AI prediction model and Fast.AI databunch, \\\n",
    "    this function finds the validation metrics (loss and accuracy) on validation data\\\n",
    "    of the databunch \"\"\"\n",
    "    model.data.train_dl = databunch.train_dl\n",
    "    model.data.valid_dl = databunch.valid_dl\n",
    "    print(\"VALIDATING THE MODEL. THE RESULT IS\")\n",
    "    validation_result = model.validate(model.data.valid_dl)\n",
    "    return validation_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20045866, tensor(0.9645)]\n"
     ]
    }
   ],
   "source": [
    "validation_result_2 = validate_on_validation_set(model=final_learner_2,databunch=validation_bunch)\n",
    "print(f\"The result of the last FULL model training is {validation_result_2})\n",
    "validation_result_1 = validate_on_validation_set(model=final_learner_1,databunch=validation_bunch)\n",
    "print(f\"The result of the FIRST FULL model training is {validation_result_1})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first number above is the cross-entropy Validation Set loss and the other number is predictive accuracy (accuracy derived from the validation set, not the training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the Model Trained on only raw features does on the validation Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the RAW FEATURES model training is [7.4402742, tensor(0.0519)]\n"
     ]
    }
   ],
   "source": [
    "raw_validation_result = validate_on_validation_set(model=raw_feature_learner,databunch=validation_bunch)\n",
    "print(f\"The result of the RAW FEATURES model training is {raw_validation_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This shows that the raw features model cannot be tested on a databunch that was created from processed data, but original databunch has to be used!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding Up Test Predictions : Have to Fix Fast.AI Bug\n",
    "These predictions are all wrong. For Some Reason, Fast.AI Is Predicting a wrong column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  71,  163,  938,  223,  311,   71,   71, 1030,  317,  951])\n"
     ]
    }
   ],
   "source": [
    "#test_probabilities,_ = final_learner_2.get_preds(DatasetType.Test,ordered=True)\n",
    "#test_predictions = torch.argmax(test_probabilities, dim=1)\n",
    "print(test_predictions[0:10])\n",
    "#data_pred = TextDataBunch.from_df(\n",
    "#  path, test_df, valid_df, test_df=None,\n",
    "#  vocab=data_clas.vocab, classes=data_clas.classes,\n",
    "#  text_cols=DEFAULT_TEXT_COLS, label_cols=DEFAULT_LABEL_COL,\n",
    "#)\n",
    "#\n",
    "##model.show_results(ds_type=DatasetType.Train)\n",
    "##model.data.add_test(test_data_full)\n",
    "#orig_classes, pred_classes = [], []\n",
    "#for b in progress_bar(model.test_dl):\n",
    "#    pred_probs = model.pred_batch(batch=b)\n",
    "#    #orig_classes += [data_clas.classes[x] for x in b[1]]\n",
    "#    #pred_classes += [data_clas.classes[x.argmax()] for x in pred_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 212,  482, 5181,  598,  762,  212,  212, 5886,  774, 5322])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target[0:10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we drop the prediction indices, we see that Fast.AI is predicting 2 columns for some reason.\n",
    "It should predict only the Category column and not give the tensor out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<01:43,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 0 is (Category 212, tensor(71), tensor([2.5375e-09, 5.2089e-08, 2.4279e-08,  ..., 1.9809e-10, 8.7067e-09,\n",
      "        8.4734e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:00<02:37,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 is (Category 482, tensor(163), tensor([2.7041e-07, 2.0830e-06, 6.7330e-08,  ..., 2.8553e-09, 1.6552e-06,\n",
      "        1.4680e-06]))\n",
      "Prediction 2 is (Category 5181, tensor(938), tensor([7.3933e-09, 1.9553e-07, 7.7729e-08,  ..., 7.4974e-11, 6.4989e-10,\n",
      "        3.5885e-10]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [00:00<02:15,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 3 is (Category 598, tensor(223), tensor([4.0987e-11, 2.0054e-09, 1.6541e-07,  ..., 1.2306e-10, 6.6816e-07,\n",
      "        8.7567e-08]))\n",
      "Prediction 4 is (Category 762, tensor(311), tensor([1.2036e-10, 1.3761e-08, 1.0309e-12,  ..., 2.9363e-13, 1.3206e-09,\n",
      "        1.3574e-11]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:01<02:21,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 5 is (Category 212, tensor(71), tensor([1.0216e-09, 1.2874e-08, 4.8393e-09,  ..., 8.3432e-11, 6.1998e-09,\n",
      "        2.1025e-09]))\n",
      "Prediction 6 is (Category 212, tensor(71), tensor([8.0099e-09, 1.1881e-07, 1.1596e-07,  ..., 4.1671e-10, 2.0704e-08,\n",
      "        1.7880e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:01<02:39,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 7 is (Category 5886, tensor(1030), tensor([8.4273e-10, 5.9291e-10, 1.5412e-08,  ..., 1.6924e-11, 3.6951e-09,\n",
      "        4.5356e-10]))\n",
      "Prediction 8 is (Category 774, tensor(317), tensor([1.2387e-09, 1.0815e-07, 7.0596e-09,  ..., 6.8684e-10, 6.5068e-09,\n",
      "        5.0885e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:01<02:35,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 9 is (Category 5322, tensor(951), tensor([1.9032e-09, 1.8962e-08, 3.1860e-07,  ..., 2.9642e-11, 2.7985e-10,\n",
      "        1.6801e-09]))\n",
      "Prediction 10 is (Category 338, tensor(109), tensor([3.0170e-05, 1.5516e-04, 1.4880e-04,  ..., 1.7925e-06, 6.4803e-05,\n",
      "        1.3253e-04]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|â         | 13/1000 [00:01<02:16,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 11 is (Category 6262, tensor(1069), tensor([5.6247e-09, 3.9610e-07, 2.2790e-10,  ..., 1.7851e-11, 2.0815e-08,\n",
      "        1.8166e-10]))\n",
      "Prediction 12 is (Category 1604, tensor(440), tensor([6.4382e-10, 1.0106e-07, 4.6156e-08,  ..., 3.1862e-10, 2.5501e-09,\n",
      "        5.8772e-09]))\n",
      "Prediction 13 is (Category 187, tensor(55), tensor([6.4318e-11, 4.8625e-10, 2.3674e-10,  ..., 4.5229e-11, 1.8094e-10,\n",
      "        4.1479e-10]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â         | 15/1000 [00:02<02:05,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 14 is (Category 187, tensor(55), tensor([3.9690e-10, 2.4529e-09, 3.5681e-09,  ..., 2.0043e-10, 8.0289e-10,\n",
      "        3.8611e-09]))\n",
      "Prediction 15 is (Category 1604, tensor(440), tensor([1.2016e-11, 1.1969e-09, 5.9463e-10,  ..., 1.0156e-11, 1.3133e-10,\n",
      "        1.1694e-10]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â         | 19/1000 [00:02<01:47,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 16 is (Category 567, tensor(200), tensor([4.1701e-07, 2.0200e-07, 2.9024e-08,  ..., 1.7551e-09, 5.7990e-08,\n",
      "        7.8653e-08]))\n",
      "Prediction 17 is (Category 187, tensor(55), tensor([2.1139e-10, 1.1197e-09, 8.9729e-10,  ..., 1.2048e-10, 7.1356e-10,\n",
      "        1.0140e-09]))\n",
      "Prediction 18 is (Category 567, tensor(200), tensor([4.0549e-08, 9.2300e-08, 1.3723e-08,  ..., 1.8751e-10, 1.7643e-09,\n",
      "        1.4545e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â         | 21/1000 [00:02<01:39,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 19 is (Category 1253, tensor(403), tensor([8.0549e-06, 4.8097e-05, 1.4370e-02,  ..., 3.4594e-07, 8.6861e-05,\n",
      "        3.8863e-05]))\n",
      "Prediction 20 is (Category 2980, tensor(638), tensor([4.6539e-06, 2.6183e-04, 3.7588e-04,  ..., 5.7173e-07, 4.9386e-06,\n",
      "        1.3559e-05]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â         | 23/1000 [00:02<02:05,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 21 is (Category 2441, tensor(519), tensor([6.4841e-09, 1.9929e-08, 3.1188e-08,  ..., 1.2187e-09, 4.6714e-07,\n",
      "        9.8371e-09]))\n",
      "Prediction 22 is (Category 2425, tensor(518), tensor([1.3892e-11, 1.5046e-10, 9.5565e-10,  ..., 1.8310e-12, 9.2062e-10,\n",
      "        8.7336e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â         | 26/1000 [00:03<01:48,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 23 is (Category 2541, tensor(530), tensor([3.2938e-09, 7.9447e-08, 5.8372e-11,  ..., 1.1090e-10, 8.4458e-12,\n",
      "        2.3384e-09]))\n",
      "Prediction 24 is (Category 567, tensor(200), tensor([6.7017e-08, 1.9958e-07, 4.2756e-08,  ..., 3.2173e-10, 5.7056e-09,\n",
      "        7.8529e-08]))\n",
      "Prediction 25 is (Category 588, tensor(217), tensor([4.6708e-08, 8.3342e-07, 2.8303e-07,  ..., 8.8186e-10, 3.6298e-10,\n",
      "        1.3937e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â         | 27/1000 [00:03<01:59,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 26 is (Category 2271, tensor(498), tensor([6.1477e-09, 1.5463e-08, 5.2608e-09,  ..., 1.8229e-10, 1.7188e-08,\n",
      "        4.4088e-09]))\n",
      "Prediction 27 is (Category 212, tensor(71), tensor([3.2490e-09, 5.8936e-08, 2.7642e-08,  ..., 3.8399e-10, 2.7430e-08,\n",
      "        1.9385e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â         | 30/1000 [00:03<02:07,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 28 is (Category 201, tensor(64), tensor([1.0854e-10, 5.3455e-10, 4.6623e-10,  ..., 2.4858e-12, 1.2582e-10,\n",
      "        4.7358e-11]))\n",
      "Prediction 29 is (Category 203, tensor(65), tensor([2.5704e-08, 5.2228e-06, 1.1441e-07,  ..., 8.5825e-10, 2.1039e-09,\n",
      "        1.1448e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â         | 32/1000 [00:04<02:07,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 30 is (Category 2271, tensor(498), tensor([1.3939e-08, 3.5268e-08, 4.6092e-08,  ..., 4.2224e-10, 7.1456e-08,\n",
      "        1.6395e-08]))\n",
      "Prediction 31 is (Category 594, tensor(219), tensor([8.7369e-10, 3.3760e-07, 5.0545e-08,  ..., 1.9205e-10, 6.3895e-08,\n",
      "        4.3259e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â         | 33/1000 [00:04<02:37,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 32 is (Category 2923, tensor(621), tensor([3.4393e-10, 2.4077e-09, 7.9917e-07,  ..., 7.8501e-11, 1.0150e-08,\n",
      "        1.7691e-10]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â         | 34/1000 [00:04<03:36,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 33 is (Category 525, tensor(180), tensor([3.0558e-08, 1.6317e-06, 2.8342e-07,  ..., 3.4243e-09, 9.4310e-08,\n",
      "        3.9092e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â         | 36/1000 [00:05<03:21,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 34 is (Category 2425, tensor(518), tensor([6.0899e-11, 5.8235e-10, 5.1802e-09,  ..., 5.8095e-12, 1.6284e-09,\n",
      "        3.0549e-08]))\n",
      "Prediction 35 is (Category 3686, tensor(759), tensor([4.9515e-08, 6.3808e-06, 6.7513e-07,  ..., 7.6439e-09, 8.7976e-10,\n",
      "        5.6784e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|â         | 38/1000 [00:05<02:47,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 36 is (Category 187, tensor(55), tensor([1.2404e-09, 8.4103e-09, 1.1487e-08,  ..., 4.8620e-10, 4.0104e-09,\n",
      "        6.8272e-09]))\n",
      "Prediction 37 is (Category 5598, tensor(990), tensor([7.6785e-10, 4.3867e-09, 4.6488e-09,  ..., 4.6035e-11, 1.2639e-09,\n",
      "        2.6194e-09]))\n",
      "Prediction 38 is (Category 212, tensor(71), tensor([4.1647e-09, 1.2398e-07, 6.5129e-08,  ..., 3.6469e-10, 2.4545e-08,\n",
      "        1.7404e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â         | 41/1000 [00:05<03:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 39 is (Category 398, tensor(122), tensor([2.1481e-05, 2.3269e-04, 5.6144e-05,  ..., 1.0645e-06, 2.8555e-05,\n",
      "        6.1816e-05]))\n",
      "Prediction 40 is (Category 775, tensor(318), tensor([1.0715e-08, 2.9368e-07, 4.4682e-09,  ..., 2.7089e-09, 1.3865e-09,\n",
      "        8.0249e-08]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|â         | 42/1000 [00:06<02:54,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 41 is (Category 2425, tensor(518), tensor([1.2353e-11, 9.7242e-11, 9.1979e-10,  ..., 1.2514e-12, 6.5678e-10,\n",
      "        7.4247e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â         | 44/1000 [00:06<03:33,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 42 is (Category 2425, tensor(518), tensor([1.6032e-10, 1.1213e-09, 9.7212e-09,  ..., 1.6518e-11, 3.3693e-09,\n",
      "        4.9469e-08]))\n",
      "Prediction 43 is (Category 212, tensor(71), tensor([3.9086e-09, 1.3894e-07, 5.4743e-08,  ..., 3.9327e-10, 1.5640e-08,\n",
      "        8.4106e-09]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â         | 45/1000 [00:06<02:26,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 44 is (Category 212, tensor(71), tensor([2.2943e-08, 2.4633e-07, 8.4883e-08,  ..., 1.8434e-09, 9.0445e-08,\n",
      "        3.3441e-08]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-1ac2381cdd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobtain_test_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_learner_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow_many_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-128-9198e15cfd23>\u001b[0m in \u001b[0;36mobtain_test_predictions\u001b[0;34m(model, features, how_many_preds)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Prediction {i} is {prediction}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhow_many_preds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-128-9198e15cfd23>\u001b[0m in \u001b[0;36mget_one_prediction\u001b[0;34m(model, feature_row)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_one_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mone_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# print(f\"Model Prediction value is: {one_prediction}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, item, return_x, batch_first, with_dropout, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mItemBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m\"Return predicted class, label and probabilities for `item`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mraw_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrab_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_item\u001b[0;34m(self, item, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;34m\"Get `item` into a batch. Optionally `detach` and `denorm`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mset_item\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;34m\"For inference, will briefly replace the dataset with one that only contains `item`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mprocess_one\u001b[0;34m(self, item, processor)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/text/data.py\u001b[0m in \u001b[0;36mprocess_one\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_all_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_join_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_fields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_bos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_eos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/text/transform.py\u001b[0m in \u001b[0;36m_process_all_1\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_all_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"Process a list of `texts` in one process.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_cases\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_cases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/text/transform.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parser\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tagger\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mblank\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mLangClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lang_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLangClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, make_doc, max_length, meta, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mmake_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_tokenizer\u001b[0;34m(cls, nlp)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0msuffix_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix_search\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minfix_finditer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfix_finditer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtoken_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_match\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.add_special_case\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.make_fused_token\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get_by_orth\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy/lang/lex_attrs.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obtain_test_predictions(model=final_learner_1, features=test_data_full, how_many_preds=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One can see clearly that the fast.AI is for some reason predicting the 2nd column (e.g. prediction 0 is tensor(71), not 212 as is the mapped id). The solution has not been found, but should definitely exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py:372:    def predict(self, item:ItemBase, return_x:bool=False, batch_first:bool=True, with_dropout:bool=False, **kwargs):\r\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py:429:    def predict_with_mc_dropout(self, item:ItemBase, with_dropout:bool=True, n_times=10, **kwargs):\r\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/text/learner.py:118:    def predict(self, text:str, n_words:int=1, no_unk:bool=True, temperature:float=1., min_p:float=None, sep:str=' ',\r\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/data_block.py:622:    def predict(self, res):\r\n"
     ]
    }
   ],
   "source": [
    "## One solution may be to change the source code since the predict function is working\n",
    "## Second option would be to get pred_batch to work properly\n",
    "path=\"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai\"\n",
    "!grep -Rn {path} -e \"def predict\"\n",
    "#--include=\\*.{py,ipynb,md} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
